from google.cloud import storage  # , bigquery
import pandas as pd
import datetime
import requests
import csv
import json
import os

# pandas display all rows
pd.set_option("display.max_rows", 50, "display.max_columns", None)

# credentials
# google credentials
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = "culture_key.json"

# --------cloud storage--------
# instantiate google cloud storage client & bucket specs
storage_client = storage.Client()
# define bucket
bucket = storage_client.get_bucket('culture_data')


def get_data_from_gcs(file):
    blob = bucket.blob(file)
    data = json.loads(blob.download_as_string())
    return data


def upload_to_gcs(blobname):
    blob = bucket.blob(blobname)
    blob.upload_from_filename(blobname)


# --------data functions--------
def sep(sep, time):
    print(sep*time)


def convert(n):
    return str(datetime.timedelta(seconds=n))

# --------crunch begin--------

# downloading data
blob = bucket.blob('MySpotifyData/StreamingHistory0.json')
data0 = json.loads(blob.download_as_string())
file0 = pd.DataFrame.from_records(data0)

blob = bucket.blob('MySpotifyData/StreamingHistory1.json')
data1 = json.loads(blob.download_as_string())
file1 = pd.DataFrame.from_records(data1)

blob = bucket.blob('MySpotifyData/StreamingHistory2.json')
data2 = json.loads(blob.download_as_string())
file2 = pd.DataFrame.from_records(data2)

# crunching
file = file0.append([file1, file2])

# cleaning : adding key + converting song consumption
file['clean duration'] = pd.to_datetime(file['msPlayed'], unit='ms')
file['text_key'] = file['artistName']+'__'+file['trackName']

"""
# uploading all clean data into bq
file.to_csv("spotify_clean_history_data.csv", index=False, quoting=csv.QUOTE_NONNUMERIC)

# uploading new version of csv to gcs
blob = bucket.blob('spotify_clean_history_data.csv')
blob.upload_from_filename('spotify_clean_history_data.csv')
print("spotify full clean data file uploaded into Gcs")
"""

# creating unique song / artist df
meta_df = file.drop(['endTime', 'msPlayed', 'clean duration'], axis=1)

print("meta df")
print(meta_df.shape)
print(type(meta_df))
print(meta_df)


# removing uniques
meta_df.drop_duplicates(inplace=True)

print("meta df--after")
print(meta_df.shape)
print(type(meta_df))
print(meta_df)

"""
meta_list = meta_df.values.tolist()
print("meta list")
print(meta_list)
"""
#  -------------------> Spotify Api section <-------------------
sep("*", 100)
# doc
# https://stmorse.github.io/journal/spotify-api.html
# https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/

blob = bucket.blob('spotify_credentials.json')
key = json.loads(blob.download_as_string())

client_id = key['client_id']
client_secret = key['client_secret']

def get_token():
    CLIENT_ID = client_id
    CLIENT_SECRET = client_secret

    AUTH_URL = 'https://accounts.spotify.com/api/token'

    # POST
    auth_response = requests.post(AUTH_URL, {
        'grant_type': 'client_credentials',
        'client_id': CLIENT_ID,
        'client_secret': CLIENT_SECRET,
    })

    # convert the response to JSON
    auth_response_data = auth_response.json()

    # save the access token
    access_token = auth_response_data['access_token']
    print(access_token)
    return access_token


token = get_token()

# token for header
headers = {
    'Authorization': 'Bearer {token}'.format(token=token)
}


def search_artist_id(artist):
    search_endpoint = 'https://api.spotify.com/v1/search'
    params = {'q': 'metallica', 'type': 'artist'}
    search_data = requests.get(url=search_endpoint,
                               params=params,
                               headers=headers)
    data = search_data.json()
    print(data)
    artist_name = data['artists']['items'][0]['name']
    artist_id = data['artists']['items'][0]['id']
    artist_genre = data['artists']['items'][0]['genres']
    return artist_id


def search_track_id(song, artist):
    try:
        search_endpoint = "https://api.spotify.com/v1/search"
        query = f'track:{song} artist:{artist}'  # no need to encode query !
        params = {'q': query, 'type': 'track'}
        search_id = requests.get(url=search_endpoint,
                                 params=params,
                                 headers=headers)
        data = search_id.json()
        return data['tracks']['items'][0]['id']

    except(IndexError, KeyError):
        return 'no data'


def search_song_feature(song_id):
    feature_endpoint = 'https://api.spotify.com/v1/audio-features/'
    params = {'ids': song_id}
    song_feature = requests.get(url=feature_endpoint,
                                params=params,
                                headers=headers)
    #print(song_feature.url)
    data = song_feature.json()
    print(data)
    if data == None:
        data = 'None'
    return data

# ------------testing values------------

trackid = search_track_id('one', 'metallica')
print(trackid)
sep("%", 100)
feature = search_song_feature(search_track_id('one', 'metallica'))
print(feature)

sep("%", 100)

# tries to apply an api call per row ... doesn't seems to work.
#print(f"meta_df['trackName'] : {meta_df['trackName'][0]}\n, meta_df['artistName'] : {meta_df['artistName'][0]}")
#meta_df['songId'] = search_track_id(meta_df['trackName'].astype(str), meta_df['artistName'].astype(str))
#print(search_track_id(meta_df['trackName'][0], meta_df['artistName'][0]))

#-----------------adding meta data from spotify api---------------

def enrich_id_files():
    # converting dataframe into list of list
    meta_list = meta_df.values.tolist()
    print(meta_list)

    counter = 0
    for item in meta_list:
        id = search_track_id(item[1], item[0])
        item.append(id)
        features = search_song_feature(item[3])  # --> extracting json from api
        #print(features)

        try:
            # setting values
            danceability = features['audio_features'][0]['danceability']
            energy = features['audio_features'][0]['energy']
            key = features['audio_features'][0]['key']
            loudness = features['audio_features'][0]['loudness']
            mode = features['audio_features'][0]['mode']
            speechiness = features['audio_features'][0]['speechiness']
            acousticness = features['audio_features'][0]['acousticness']
            instrumentalness = features['audio_features'][0]['instrumentalness']
            liveness = features['audio_features'][0]['liveness']
            valence = features['audio_features'][0]['valence']
            tempo = features['audio_features'][0]['tempo']
            type = features['audio_features'][0]['type']
            duration_ms = features['audio_features'][0]['duration_ms']

            # adding values to the list
            item.append(danceability)
            item.append(energy)
            item.append(key)
            item.append(loudness)
            item.append(mode)
            item.append(speechiness)
            item.append(acousticness)
            item.append(instrumentalness)
            item.append(liveness)
            item.append(valence)
            item.append(tempo)
            item.append(type)
            item.append(duration_ms)
        except:
            print('exception')
            # adding values to the list
            item.append(0)
            item.append(0)
            item.append('NaN')
            item.append(0)
            item.append(0)
            item.append(0)
            item.append(0)
            item.append(0)
            item.append(0)
            item.append(0)
            item.append(0)
            item.append('NaN')
            item.append(0)

        # unmute following line for qa purpose
        #print(f"song : {item[1]}, artist : {item[0]}, id : {id}, features : {features}")
        counter += 1
        print(f"{round((counter / 5004)*100, 4)}% done")

    print(meta_list)

    with open('meta_song_ids.csv', 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)
        header = ['artistName', 'trackName', 'text_key', 'trackId', 'danceability',
                          'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',
                          'instrumentalness', 'liveness', 'valence', 'tempo', 'type', 'duration_ms']
        writer.writerow(header)
        writer.writerows(meta_list)

    return meta_list


enrich_id_files()

# uploading new version of csv to gcs
blob = bucket.blob('meta_song_ids.csv')
blob.upload_from_filename('meta_song_ids.csv')
print("file uploaded into Gcs")
"""

print(type(file))

df = pd.read_csv('gs://bucket/your_path.csv')
meta_data_df = pd.read_csv('gs://culture_data/meta_song_ids.csv')
print(type(meta_data_df))


blob = bucket.blob('meta_song_ids.csv')
meta_data = json.loads(blob.download_as_string())
print(type(meta_data))
#meta_data_df = pd.DataFrame.(meta_data)

# downloading data
blob = bucket.blob('MySpotifyData/StreamingHistory0.json')
data0 = json.loads(blob.download_as_string())
file0 = pd.DataFrame.from_records(data0)
"""
